{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaAL0AMl1PDj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b40e9232-f43b-4d03-ee90-0b8ddc3696ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load data\n",
        "import pandas as pd\n",
        "data=pd.read_table('/content/drive/MyDrive/ML/input_file/finalexam/kor.txt')\n",
        "data"
      ],
      "metadata": {
        "id": "Gl3UtOe01SjX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "49112d86-1db7-4834-e2b3-780569f3740a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    Go.  \\\n",
              "0                                                   Hi.   \n",
              "1                                                  Run!   \n",
              "2                                                  Run.   \n",
              "3                                                  Who?   \n",
              "4                                                  Wow!   \n",
              "...                                                 ...   \n",
              "5886  I started a new blog. I'll do my best not to b...   \n",
              "5887  I think it's a shame that some foreign languag...   \n",
              "5888  And the good news is that today the economy is...   \n",
              "5889  If someone who doesn't know your background sa...   \n",
              "5890  Doubtless there exists in this world precisely...   \n",
              "\n",
              "                                                     가.  \\\n",
              "0                                                   안녕.   \n",
              "1                                                   뛰어!   \n",
              "2                                                   뛰어.   \n",
              "3                                                   누구?   \n",
              "4                                                   우와!   \n",
              "...                                                 ...   \n",
              "5886  난 블로그를 시작했어. 블로그를 초반에만 반짝 많이 하다가 관두는 사람처럼은 되지 ...   \n",
              "5887  몇몇 외국어 선생님이 한 번도 원어민과 공부해본 적도 없으면서 대학을 나올 수 있었...   \n",
              "5888  다음으로 좋은 소식은 오늘 경제가 재성장한다는 것입니다. 임금, 소득, 집값, 퇴직...   \n",
              "5889  만일 네 사정도 잘 모르는 사람이 원어민 같다고 말한다면 그건 그 사람이 네가 원어...   \n",
              "5890  의심의 여지 없이 세상에는 어떤 남자이든 정확히 딱 알맞는 여자와 결혼하거나 그 반...   \n",
              "\n",
              "     CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8363271 (Eunhee)  \n",
              "0     CC-BY 2.0 (France) Attribution: tatoeba.org #5...                             \n",
              "1     CC-BY 2.0 (France) Attribution: tatoeba.org #9...                             \n",
              "2     CC-BY 2.0 (France) Attribution: tatoeba.org #4...                             \n",
              "3     CC-BY 2.0 (France) Attribution: tatoeba.org #2...                             \n",
              "4     CC-BY 2.0 (France) Attribution: tatoeba.org #5...                             \n",
              "...                                                 ...                             \n",
              "5886  CC-BY 2.0 (France) Attribution: tatoeba.org #1...                             \n",
              "5887  CC-BY 2.0 (France) Attribution: tatoeba.org #9...                             \n",
              "5888  CC-BY 2.0 (France) Attribution: tatoeba.org #5...                             \n",
              "5889  CC-BY 2.0 (France) Attribution: tatoeba.org #9...                             \n",
              "5890  CC-BY 2.0 (France) Attribution: tatoeba.org #7...                             \n",
              "\n",
              "[5891 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35111762-596f-4b35-9bc4-9b9676575ef1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Go.</th>\n",
              "      <th>가.</th>\n",
              "      <th>CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) &amp; #8363271 (Eunhee)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>안녕.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run!</td>\n",
              "      <td>뛰어!</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run.</td>\n",
              "      <td>뛰어.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Who?</td>\n",
              "      <td>누구?</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>우와!</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5886</th>\n",
              "      <td>I started a new blog. I'll do my best not to b...</td>\n",
              "      <td>난 블로그를 시작했어. 블로그를 초반에만 반짝 많이 하다가 관두는 사람처럼은 되지 ...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5887</th>\n",
              "      <td>I think it's a shame that some foreign languag...</td>\n",
              "      <td>몇몇 외국어 선생님이 한 번도 원어민과 공부해본 적도 없으면서 대학을 나올 수 있었...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5888</th>\n",
              "      <td>And the good news is that today the economy is...</td>\n",
              "      <td>다음으로 좋은 소식은 오늘 경제가 재성장한다는 것입니다. 임금, 소득, 집값, 퇴직...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5889</th>\n",
              "      <td>If someone who doesn't know your background sa...</td>\n",
              "      <td>만일 네 사정도 잘 모르는 사람이 원어민 같다고 말한다면 그건 그 사람이 네가 원어...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5890</th>\n",
              "      <td>Doubtless there exists in this world precisely...</td>\n",
              "      <td>의심의 여지 없이 세상에는 어떤 남자이든 정확히 딱 알맞는 여자와 결혼하거나 그 반...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #7...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5891 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35111762-596f-4b35-9bc4-9b9676575ef1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-35111762-596f-4b35-9bc4-9b9676575ef1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-35111762-596f-4b35-9bc4-9b9676575ef1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bb77f574-ca72-4cf3-a97c-191dd923c7ba\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bb77f574-ca72-4cf3-a97c-191dd923c7ba')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bb77f574-ca72-4cf3-a97c-191dd923c7ba button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because the convert file is not compatible to Korean, the Korean can be shown differnt keywords. Thus I upload with my ipynb file."
      ],
      "metadata": {
        "id": "v_Ewr8lJeUBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ram crash happened if I use all data\n",
        "# So I use a part of total data\n",
        "X=data.iloc[:2000,0]\n",
        "Y=data.iloc[:2000,1]"
      ],
      "metadata": {
        "id": "CzowKIUJDJvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "# Toy dataset for English to Korean translation\n",
        "input_texts = X\n",
        "target_texts = Y\n",
        "print(X[:10])\n",
        "print(Y[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvf0QQYACOu4",
        "outputId": "8c7f2057-99ea-41ba-bbac-b98b3afe2375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      Hi.\n",
            "1     Run!\n",
            "2     Run.\n",
            "3     Who?\n",
            "4     Wow!\n",
            "5    Duck!\n",
            "6    Fire!\n",
            "7    Help!\n",
            "8    Hide.\n",
            "9    Jump!\n",
            "Name: Go., dtype: object\n",
            "0     안녕.\n",
            "1     뛰어!\n",
            "2     뛰어.\n",
            "3     누구?\n",
            "4     우와!\n",
            "5     숙여!\n",
            "6      쏴!\n",
            "7    도와줘!\n",
            "8     숨어.\n",
            "9     점프!\n",
            "Name: 가., dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_vocab = set(char for word in input_texts for char in word)\n",
        "target_vocab = set(char for word in target_texts for char in word)\n",
        "#print(input_vocab)\n",
        "#print(target_vocab)\n",
        "\n",
        "input_vocab_size = len(input_vocab)\n",
        "target_vocab_size = len(target_vocab)\n",
        "print(input_vocab_size)\n",
        "print(target_vocab_size)\n",
        "\n",
        "input_max_len = max(len(word) for word in input_texts)\n",
        "target_max_len = max(len(word) for word in target_texts) + 1  # +1 for the end token\n",
        "print(input_max_len)\n",
        "print(target_max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2mr3P7AHunV",
        "outputId": "a458e32e-e713-4b13-bf52-37ad59341974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n",
            "711\n",
            "21\n",
            "23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create mapping from characters to indices and vice versa\n",
        "input_char_index = dict((char, i) for i, char in enumerate(input_vocab))\n",
        "target_char_index = dict((char, i) for i, char in enumerate(target_vocab))\n",
        "reverse_input_char_index = dict((i, char) for i, char in enumerate(input_vocab))\n",
        "reverse_target_char_index = dict((i, char) for i, char in enumerate(target_vocab))\n",
        "\n",
        "# Prepare the data\n",
        "encoder_input_data = np.zeros((len(input_texts), input_max_len, input_vocab_size), dtype='float32')    #that is, size(2000,21,65)\n",
        "decoder_input_data = np.zeros((len(input_texts), target_max_len, target_vocab_size), dtype='float32')  #that is, size(2000,23,711)\n",
        "decoder_target_data = np.zeros((len(input_texts), target_max_len, target_vocab_size), dtype='float32') #that is, size(2000,23,711)\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_char_index[char]] = 1.0                   # set component of encoder input data which has char 1\n",
        "    for t, char in enumerate(target_text):\n",
        "        decoder_input_data[i, t, target_char_index[char]] = 1.0                  # set component of decoder input data which has char 1\n",
        "        if t > 0:   # for nonzero t\n",
        "            decoder_target_data[i, t - 1, target_char_index[char]] = 1.0         # set previous component of decoder input data which has char 1\n"
      ],
      "metadata": {
        "id": "PzoXyZk8HoR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_char_index['Y'])\n",
        "print(target_char_index['좁'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWXHQ253YGI-",
        "outputId": "64e0888e-86df-4d81-ab30-128c5972ddff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57\n",
            "661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Seq2Seq model\n",
        "latent_dim = 256\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None, input_vocab_size))\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)   #set hidden state and others\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None, target_vocab_size))\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)  #recieve the context from encoder\n",
        "decoder_dense = Dense(target_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)               # seq2seq\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "84cxVRFWH7vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, epochs=800, batch_size=20)\n",
        "#epochs is set 20 despite low accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3vhUkKMIAfo",
        "outputId": "1d1171c6-a00d-4467-e5ba-8018e9c10e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 1.1659 - accuracy: 0.1560\n",
            "Epoch 2/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 1.1055 - accuracy: 0.1635\n",
            "Epoch 3/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 1.0700 - accuracy: 0.1668\n",
            "Epoch 4/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 1.0338 - accuracy: 0.1725\n",
            "Epoch 5/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 1.0085 - accuracy: 0.1757\n",
            "Epoch 6/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.9863 - accuracy: 0.1787\n",
            "Epoch 7/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.9707 - accuracy: 0.1805\n",
            "Epoch 8/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.9579 - accuracy: 0.1832\n",
            "Epoch 9/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.9421 - accuracy: 0.1850\n",
            "Epoch 10/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.9286 - accuracy: 0.1881\n",
            "Epoch 11/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.9200 - accuracy: 0.1893\n",
            "Epoch 12/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.9095 - accuracy: 0.1905\n",
            "Epoch 13/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.9014 - accuracy: 0.1924\n",
            "Epoch 14/800\n",
            "100/100 [==============================] - 15s 148ms/step - loss: 0.8913 - accuracy: 0.1944\n",
            "Epoch 15/800\n",
            "100/100 [==============================] - 15s 148ms/step - loss: 0.8847 - accuracy: 0.1947\n",
            "Epoch 16/800\n",
            "100/100 [==============================] - 15s 148ms/step - loss: 0.8762 - accuracy: 0.1962\n",
            "Epoch 17/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.8677 - accuracy: 0.1977\n",
            "Epoch 18/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.8630 - accuracy: 0.1983\n",
            "Epoch 19/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.8554 - accuracy: 0.1999\n",
            "Epoch 20/800\n",
            "100/100 [==============================] - 15s 148ms/step - loss: 0.8617 - accuracy: 0.1991\n",
            "Epoch 21/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.8450 - accuracy: 0.2012\n",
            "Epoch 22/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.8417 - accuracy: 0.2018\n",
            "Epoch 23/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.8352 - accuracy: 0.2034\n",
            "Epoch 24/800\n",
            "100/100 [==============================] - 15s 148ms/step - loss: 0.8233 - accuracy: 0.2051\n",
            "Epoch 25/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.8163 - accuracy: 0.2059\n",
            "Epoch 26/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.8086 - accuracy: 0.2070\n",
            "Epoch 27/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.8067 - accuracy: 0.2078\n",
            "Epoch 28/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.8039 - accuracy: 0.2082\n",
            "Epoch 29/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.8013 - accuracy: 0.2078\n",
            "Epoch 30/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.7949 - accuracy: 0.2089\n",
            "Epoch 31/800\n",
            "100/100 [==============================] - 15s 148ms/step - loss: 0.7821 - accuracy: 0.2109\n",
            "Epoch 32/800\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.7770 - accuracy: 0.2124\n",
            "Epoch 33/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.7810 - accuracy: 0.2122\n",
            "Epoch 34/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.7854 - accuracy: 0.2111\n",
            "Epoch 35/800\n",
            "100/100 [==============================] - 15s 148ms/step - loss: 0.7966 - accuracy: 0.2092\n",
            "Epoch 36/800\n",
            "100/100 [==============================] - 15s 148ms/step - loss: 0.7692 - accuracy: 0.2134\n",
            "Epoch 37/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.7576 - accuracy: 0.2146\n",
            "Epoch 38/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.7468 - accuracy: 0.2168\n",
            "Epoch 39/800\n",
            "100/100 [==============================] - 15s 148ms/step - loss: 0.7361 - accuracy: 0.2187\n",
            "Epoch 40/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.7571 - accuracy: 0.2161\n",
            "Epoch 41/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.7779 - accuracy: 0.2112\n",
            "Epoch 42/800\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 0.7318 - accuracy: 0.2201\n",
            "Epoch 43/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.7192 - accuracy: 0.2217\n",
            "Epoch 44/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.7119 - accuracy: 0.2232\n",
            "Epoch 45/800\n",
            "100/100 [==============================] - 15s 148ms/step - loss: 0.7085 - accuracy: 0.2242\n",
            "Epoch 46/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.7419 - accuracy: 0.2180\n",
            "Epoch 47/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.7095 - accuracy: 0.2234\n",
            "Epoch 48/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.7086 - accuracy: 0.2237\n",
            "Epoch 49/800\n",
            "100/100 [==============================] - 15s 148ms/step - loss: 0.6883 - accuracy: 0.2280\n",
            "Epoch 50/800\n",
            "100/100 [==============================] - 15s 148ms/step - loss: 0.8722 - accuracy: 0.1983\n",
            "Epoch 51/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.7252 - accuracy: 0.2202\n",
            "Epoch 52/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.7084 - accuracy: 0.2241\n",
            "Epoch 53/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.7139 - accuracy: 0.2238\n",
            "Epoch 54/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.6938 - accuracy: 0.2272\n",
            "Epoch 55/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.7220 - accuracy: 0.2220\n",
            "Epoch 56/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.6652 - accuracy: 0.2326\n",
            "Epoch 57/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.6541 - accuracy: 0.2345\n",
            "Epoch 58/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.6476 - accuracy: 0.2360\n",
            "Epoch 59/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.6409 - accuracy: 0.2370\n",
            "Epoch 60/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.6373 - accuracy: 0.2380\n",
            "Epoch 61/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.6527 - accuracy: 0.2360\n",
            "Epoch 62/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.6696 - accuracy: 0.2312\n",
            "Epoch 63/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.6340 - accuracy: 0.2377\n",
            "Epoch 64/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.6208 - accuracy: 0.2407\n",
            "Epoch 65/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.6125 - accuracy: 0.2419\n",
            "Epoch 66/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.6049 - accuracy: 0.2434\n",
            "Epoch 67/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.5974 - accuracy: 0.2450\n",
            "Epoch 68/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.5935 - accuracy: 0.2464\n",
            "Epoch 69/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.5889 - accuracy: 0.2471\n",
            "Epoch 70/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.7384 - accuracy: 0.2193\n",
            "Epoch 71/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.6385 - accuracy: 0.2349\n",
            "Epoch 72/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.5996 - accuracy: 0.2438\n",
            "Epoch 73/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.5833 - accuracy: 0.2478\n",
            "Epoch 74/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.5968 - accuracy: 0.2450\n",
            "Epoch 75/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.5690 - accuracy: 0.2506\n",
            "Epoch 76/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.5631 - accuracy: 0.2521\n",
            "Epoch 77/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.5736 - accuracy: 0.2513\n",
            "Epoch 78/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.6907 - accuracy: 0.2243\n",
            "Epoch 79/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.5820 - accuracy: 0.2474\n",
            "Epoch 80/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.5544 - accuracy: 0.2536\n",
            "Epoch 81/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.5450 - accuracy: 0.2552\n",
            "Epoch 82/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.5366 - accuracy: 0.2582\n",
            "Epoch 83/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.5299 - accuracy: 0.2590\n",
            "Epoch 84/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.5255 - accuracy: 0.2597\n",
            "Epoch 85/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.5186 - accuracy: 0.2618\n",
            "Epoch 86/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.6164 - accuracy: 0.2426\n",
            "Epoch 87/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.7944 - accuracy: 0.2068\n",
            "Epoch 88/800\n",
            "100/100 [==============================] - 15s 148ms/step - loss: 0.7110 - accuracy: 0.2203\n",
            "Epoch 89/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.6546 - accuracy: 0.2333\n",
            "Epoch 90/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.5692 - accuracy: 0.2496\n",
            "Epoch 91/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.5385 - accuracy: 0.2558\n",
            "Epoch 92/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.5228 - accuracy: 0.2582\n",
            "Epoch 93/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.5127 - accuracy: 0.2612\n",
            "Epoch 94/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.5037 - accuracy: 0.2632\n",
            "Epoch 95/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.4960 - accuracy: 0.2653\n",
            "Epoch 96/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.4880 - accuracy: 0.2664\n",
            "Epoch 97/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.4821 - accuracy: 0.2680\n",
            "Epoch 98/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.4768 - accuracy: 0.2697\n",
            "Epoch 99/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.4721 - accuracy: 0.2699\n",
            "Epoch 100/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.4671 - accuracy: 0.2718\n",
            "Epoch 101/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.4637 - accuracy: 0.2731\n",
            "Epoch 102/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.4567 - accuracy: 0.2743\n",
            "Epoch 103/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.4532 - accuracy: 0.2749\n",
            "Epoch 104/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.4498 - accuracy: 0.2753\n",
            "Epoch 105/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.4476 - accuracy: 0.2759\n",
            "Epoch 106/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.4411 - accuracy: 0.2773\n",
            "Epoch 107/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.4340 - accuracy: 0.2795\n",
            "Epoch 108/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.5997 - accuracy: 0.2450\n",
            "Epoch 109/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.6584 - accuracy: 0.2302\n",
            "Epoch 110/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.5076 - accuracy: 0.2599\n",
            "Epoch 111/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.4669 - accuracy: 0.2694\n",
            "Epoch 112/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.4430 - accuracy: 0.2762\n",
            "Epoch 113/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.4223 - accuracy: 0.2822\n",
            "Epoch 114/800\n",
            "100/100 [==============================] - 15s 148ms/step - loss: 0.4141 - accuracy: 0.2828\n",
            "Epoch 115/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.4064 - accuracy: 0.2853\n",
            "Epoch 116/800\n",
            "100/100 [==============================] - 15s 148ms/step - loss: 0.4036 - accuracy: 0.2865\n",
            "Epoch 117/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.3998 - accuracy: 0.2870\n",
            "Epoch 118/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.4110 - accuracy: 0.2834\n",
            "Epoch 119/800\n",
            "100/100 [==============================] - 14s 143ms/step - loss: 0.4923 - accuracy: 0.2653\n",
            "Epoch 120/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.4652 - accuracy: 0.2685\n",
            "Epoch 121/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.3979 - accuracy: 0.2863\n",
            "Epoch 122/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.3869 - accuracy: 0.2896\n",
            "Epoch 123/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.3843 - accuracy: 0.2911\n",
            "Epoch 124/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.3760 - accuracy: 0.2926\n",
            "Epoch 125/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.3674 - accuracy: 0.2938\n",
            "Epoch 126/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.3650 - accuracy: 0.2955\n",
            "Epoch 127/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.3589 - accuracy: 0.2968\n",
            "Epoch 128/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.3585 - accuracy: 0.2964\n",
            "Epoch 129/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.3536 - accuracy: 0.2977\n",
            "Epoch 130/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.3516 - accuracy: 0.2975\n",
            "Epoch 131/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.4006 - accuracy: 0.2861\n",
            "Epoch 132/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.5446 - accuracy: 0.2521\n",
            "Epoch 133/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.5500 - accuracy: 0.2479\n",
            "Epoch 134/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.4325 - accuracy: 0.2743\n",
            "Epoch 135/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.3747 - accuracy: 0.2908\n",
            "Epoch 136/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.3919 - accuracy: 0.2879\n",
            "Epoch 137/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.3591 - accuracy: 0.2950\n",
            "Epoch 138/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.3423 - accuracy: 0.3003\n",
            "Epoch 139/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.3324 - accuracy: 0.3026\n",
            "Epoch 140/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.3260 - accuracy: 0.3052\n",
            "Epoch 141/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.3667 - accuracy: 0.2941\n",
            "Epoch 142/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.3431 - accuracy: 0.2994\n",
            "Epoch 143/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.4706 - accuracy: 0.2762\n",
            "Epoch 144/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.7945 - accuracy: 0.2039\n",
            "Epoch 145/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.5955 - accuracy: 0.2393\n",
            "Epoch 146/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.4516 - accuracy: 0.2687\n",
            "Epoch 147/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.3854 - accuracy: 0.2858\n",
            "Epoch 148/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.3527 - accuracy: 0.2947\n",
            "Epoch 149/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.3321 - accuracy: 0.3017\n",
            "Epoch 150/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.3195 - accuracy: 0.3052\n",
            "Epoch 151/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.3111 - accuracy: 0.3077\n",
            "Epoch 152/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.3040 - accuracy: 0.3094\n",
            "Epoch 153/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.2983 - accuracy: 0.3105\n",
            "Epoch 154/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.2938 - accuracy: 0.3117\n",
            "Epoch 155/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.2892 - accuracy: 0.3126\n",
            "Epoch 156/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.2860 - accuracy: 0.3141\n",
            "Epoch 157/800\n",
            "100/100 [==============================] - 15s 148ms/step - loss: 0.2837 - accuracy: 0.3145\n",
            "Epoch 158/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.2803 - accuracy: 0.3151\n",
            "Epoch 159/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.2742 - accuracy: 0.3176\n",
            "Epoch 160/800\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 0.2702 - accuracy: 0.3182\n",
            "Epoch 161/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.2697 - accuracy: 0.3180\n",
            "Epoch 162/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.2687 - accuracy: 0.3185\n",
            "Epoch 163/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.2670 - accuracy: 0.3186\n",
            "Epoch 164/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.2629 - accuracy: 0.3202\n",
            "Epoch 165/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.2599 - accuracy: 0.3209\n",
            "Epoch 166/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.2592 - accuracy: 0.3209\n",
            "Epoch 167/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.2533 - accuracy: 0.3223\n",
            "Epoch 168/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.2540 - accuracy: 0.3217\n",
            "Epoch 169/800\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.5883 - accuracy: 0.2459\n",
            "Epoch 170/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.5287 - accuracy: 0.2512\n",
            "Epoch 171/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.4631 - accuracy: 0.2684\n",
            "Epoch 172/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.5901 - accuracy: 0.2403\n",
            "Epoch 173/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.3891 - accuracy: 0.2832\n",
            "Epoch 174/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.3242 - accuracy: 0.3004\n",
            "Epoch 175/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.2913 - accuracy: 0.3102\n",
            "Epoch 176/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.2737 - accuracy: 0.3162\n",
            "Epoch 177/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.2620 - accuracy: 0.3189\n",
            "Epoch 178/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.2539 - accuracy: 0.3213\n",
            "Epoch 179/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.2469 - accuracy: 0.3234\n",
            "Epoch 180/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.2407 - accuracy: 0.3260\n",
            "Epoch 181/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.2361 - accuracy: 0.3263\n",
            "Epoch 182/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.2319 - accuracy: 0.3280\n",
            "Epoch 183/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.2273 - accuracy: 0.3288\n",
            "Epoch 184/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.2244 - accuracy: 0.3296\n",
            "Epoch 185/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.2214 - accuracy: 0.3305\n",
            "Epoch 186/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.2201 - accuracy: 0.3313\n",
            "Epoch 187/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.2248 - accuracy: 0.3302\n",
            "Epoch 188/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.2181 - accuracy: 0.3313\n",
            "Epoch 189/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.2187 - accuracy: 0.3317\n",
            "Epoch 190/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.2153 - accuracy: 0.3317\n",
            "Epoch 191/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.2088 - accuracy: 0.3338\n",
            "Epoch 192/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.2074 - accuracy: 0.3345\n",
            "Epoch 193/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.2075 - accuracy: 0.3343\n",
            "Epoch 194/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.5269 - accuracy: 0.2565\n",
            "Epoch 195/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.2751 - accuracy: 0.3125\n",
            "Epoch 196/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.2300 - accuracy: 0.3274\n",
            "Epoch 197/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.2114 - accuracy: 0.3327\n",
            "Epoch 198/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.2022 - accuracy: 0.3351\n",
            "Epoch 199/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.2011 - accuracy: 0.3357\n",
            "Epoch 200/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.3277 - accuracy: 0.3017\n",
            "Epoch 201/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.2094 - accuracy: 0.3321\n",
            "Epoch 202/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.1968 - accuracy: 0.3368\n",
            "Epoch 203/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.1903 - accuracy: 0.3385\n",
            "Epoch 204/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.1885 - accuracy: 0.3387\n",
            "Epoch 205/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.1889 - accuracy: 0.3390\n",
            "Epoch 206/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.2515 - accuracy: 0.3218\n",
            "Epoch 207/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.6066 - accuracy: 0.2385\n",
            "Epoch 208/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.3389 - accuracy: 0.2946\n",
            "Epoch 209/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.3487 - accuracy: 0.3011\n",
            "Epoch 210/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.8311 - accuracy: 0.2010\n",
            "Epoch 211/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.5200 - accuracy: 0.2537\n",
            "Epoch 212/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.3980 - accuracy: 0.2812\n",
            "Epoch 213/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.4479 - accuracy: 0.2743\n",
            "Epoch 214/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.3328 - accuracy: 0.2977\n",
            "Epoch 215/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.2698 - accuracy: 0.3143\n",
            "Epoch 216/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.2415 - accuracy: 0.3222\n",
            "Epoch 217/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.2259 - accuracy: 0.3273\n",
            "Epoch 218/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.2151 - accuracy: 0.3312\n",
            "Epoch 219/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.2076 - accuracy: 0.3325\n",
            "Epoch 220/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.2010 - accuracy: 0.3352\n",
            "Epoch 221/800\n",
            "100/100 [==============================] - 14s 144ms/step - loss: 0.1962 - accuracy: 0.3362\n",
            "Epoch 222/800\n",
            "100/100 [==============================] - 15s 148ms/step - loss: 0.1915 - accuracy: 0.3371\n",
            "Epoch 223/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.1874 - accuracy: 0.3385\n",
            "Epoch 224/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.1927 - accuracy: 0.3370\n",
            "Epoch 225/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.1872 - accuracy: 0.3381\n",
            "Epoch 226/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.1809 - accuracy: 0.3400\n",
            "Epoch 227/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.1763 - accuracy: 0.3414\n",
            "Epoch 228/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.1727 - accuracy: 0.3415\n",
            "Epoch 229/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.1707 - accuracy: 0.3432\n",
            "Epoch 230/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.1689 - accuracy: 0.3425\n",
            "Epoch 231/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.1657 - accuracy: 0.3437\n",
            "Epoch 232/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.1652 - accuracy: 0.3441\n",
            "Epoch 233/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.1649 - accuracy: 0.3446\n",
            "Epoch 234/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.1643 - accuracy: 0.3448\n",
            "Epoch 235/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.1632 - accuracy: 0.3445\n",
            "Epoch 236/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.1608 - accuracy: 0.3454\n",
            "Epoch 237/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.1599 - accuracy: 0.3452\n",
            "Epoch 238/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.2710 - accuracy: 0.3190\n",
            "Epoch 239/800\n",
            "100/100 [==============================] - 14s 145ms/step - loss: 0.6665 - accuracy: 0.2337\n",
            "Epoch 240/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.4766 - accuracy: 0.2637\n",
            "Epoch 241/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.3179 - accuracy: 0.2998\n",
            "Epoch 242/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.3195 - accuracy: 0.3035\n",
            "Epoch 243/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.2367 - accuracy: 0.3230\n",
            "Epoch 244/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.1975 - accuracy: 0.3339\n",
            "Epoch 245/800\n",
            "100/100 [==============================] - 15s 146ms/step - loss: 0.1814 - accuracy: 0.3386\n",
            "Epoch 246/800\n",
            "100/100 [==============================] - 15s 145ms/step - loss: 0.1718 - accuracy: 0.3421\n",
            "Epoch 247/800\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 0.1646 - accuracy: 0.3435\n",
            "Epoch 248/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.1603 - accuracy: 0.3453\n",
            "Epoch 249/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1568 - accuracy: 0.3454\n",
            "Epoch 250/800\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 0.1565 - accuracy: 0.3452\n",
            "Epoch 251/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1529 - accuracy: 0.3468\n",
            "Epoch 252/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.1501 - accuracy: 0.3472\n",
            "Epoch 253/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.1480 - accuracy: 0.3477\n",
            "Epoch 254/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.1467 - accuracy: 0.3482\n",
            "Epoch 255/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.3039 - accuracy: 0.3027\n",
            "Epoch 256/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.1847 - accuracy: 0.3363\n",
            "Epoch 257/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1617 - accuracy: 0.3433\n",
            "Epoch 258/800\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.1502 - accuracy: 0.3468\n",
            "Epoch 259/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.1444 - accuracy: 0.3485\n",
            "Epoch 260/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1417 - accuracy: 0.3485\n",
            "Epoch 261/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1398 - accuracy: 0.3494\n",
            "Epoch 262/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.1421 - accuracy: 0.3488\n",
            "Epoch 263/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.1392 - accuracy: 0.3494\n",
            "Epoch 264/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1374 - accuracy: 0.3497\n",
            "Epoch 265/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.1352 - accuracy: 0.3499\n",
            "Epoch 266/800\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.1346 - accuracy: 0.3498\n",
            "Epoch 267/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1338 - accuracy: 0.3506\n",
            "Epoch 268/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.1335 - accuracy: 0.3509\n",
            "Epoch 269/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1345 - accuracy: 0.3506\n",
            "Epoch 270/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1403 - accuracy: 0.3488\n",
            "Epoch 271/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.2690 - accuracy: 0.3135\n",
            "Epoch 272/800\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 0.2843 - accuracy: 0.3075\n",
            "Epoch 273/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.1723 - accuracy: 0.3394\n",
            "Epoch 274/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1476 - accuracy: 0.3475\n",
            "Epoch 275/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.1374 - accuracy: 0.3495\n",
            "Epoch 276/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1321 - accuracy: 0.3508\n",
            "Epoch 277/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1291 - accuracy: 0.3518\n",
            "Epoch 278/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.1269 - accuracy: 0.3523\n",
            "Epoch 279/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.1246 - accuracy: 0.3527\n",
            "Epoch 280/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.1245 - accuracy: 0.3522\n",
            "Epoch 281/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1230 - accuracy: 0.3528\n",
            "Epoch 282/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1228 - accuracy: 0.3530\n",
            "Epoch 283/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1388 - accuracy: 0.3492\n",
            "Epoch 284/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.1325 - accuracy: 0.3503\n",
            "Epoch 285/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1272 - accuracy: 0.3516\n",
            "Epoch 286/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1229 - accuracy: 0.3527\n",
            "Epoch 287/800\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.1195 - accuracy: 0.3535\n",
            "Epoch 288/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.1187 - accuracy: 0.3536\n",
            "Epoch 289/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1187 - accuracy: 0.3533\n",
            "Epoch 290/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.3270 - accuracy: 0.2956\n",
            "Epoch 291/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.2319 - accuracy: 0.3217\n",
            "Epoch 292/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.1517 - accuracy: 0.3442\n",
            "Epoch 293/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.1295 - accuracy: 0.3513\n",
            "Epoch 294/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.1207 - accuracy: 0.3528\n",
            "Epoch 295/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.1170 - accuracy: 0.3539\n",
            "Epoch 296/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1152 - accuracy: 0.3540\n",
            "Epoch 297/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1128 - accuracy: 0.3548\n",
            "Epoch 298/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1255 - accuracy: 0.3516\n",
            "Epoch 299/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1254 - accuracy: 0.3514\n",
            "Epoch 300/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1176 - accuracy: 0.3534\n",
            "Epoch 301/800\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 0.1123 - accuracy: 0.3549\n",
            "Epoch 302/800\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.1099 - accuracy: 0.3556\n",
            "Epoch 303/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1083 - accuracy: 0.3555\n",
            "Epoch 304/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1075 - accuracy: 0.3553\n",
            "Epoch 305/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1082 - accuracy: 0.3558\n",
            "Epoch 306/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1081 - accuracy: 0.3555\n",
            "Epoch 307/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1100 - accuracy: 0.3557\n",
            "Epoch 308/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1078 - accuracy: 0.3553\n",
            "Epoch 309/800\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.1067 - accuracy: 0.3563\n",
            "Epoch 310/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1101 - accuracy: 0.3553\n",
            "Epoch 311/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.4657 - accuracy: 0.2794\n",
            "Epoch 312/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.5379 - accuracy: 0.2506\n",
            "Epoch 313/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.5092 - accuracy: 0.2616\n",
            "Epoch 314/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.4360 - accuracy: 0.2693\n",
            "Epoch 315/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.2670 - accuracy: 0.3092\n",
            "Epoch 316/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.1946 - accuracy: 0.3304\n",
            "Epoch 317/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.1627 - accuracy: 0.3405\n",
            "Epoch 318/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1441 - accuracy: 0.3466\n",
            "Epoch 319/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1415 - accuracy: 0.3469\n",
            "Epoch 320/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1343 - accuracy: 0.3493\n",
            "Epoch 321/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1213 - accuracy: 0.3527\n",
            "Epoch 322/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.1163 - accuracy: 0.3540\n",
            "Epoch 323/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.1136 - accuracy: 0.3552\n",
            "Epoch 324/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.1111 - accuracy: 0.3552\n",
            "Epoch 325/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.1089 - accuracy: 0.3557\n",
            "Epoch 326/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1074 - accuracy: 0.3560\n",
            "Epoch 327/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.1061 - accuracy: 0.3567\n",
            "Epoch 328/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1044 - accuracy: 0.3568\n",
            "Epoch 329/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1033 - accuracy: 0.3565\n",
            "Epoch 330/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1020 - accuracy: 0.3569\n",
            "Epoch 331/800\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.1016 - accuracy: 0.3571\n",
            "Epoch 332/800\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 0.1005 - accuracy: 0.3574\n",
            "Epoch 333/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.1003 - accuracy: 0.3575\n",
            "Epoch 334/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.0996 - accuracy: 0.3572\n",
            "Epoch 335/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0989 - accuracy: 0.3570\n",
            "Epoch 336/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1015 - accuracy: 0.3569\n",
            "Epoch 337/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0999 - accuracy: 0.3573\n",
            "Epoch 338/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0979 - accuracy: 0.3576\n",
            "Epoch 339/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.0971 - accuracy: 0.3574\n",
            "Epoch 340/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0964 - accuracy: 0.3579\n",
            "Epoch 341/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.0954 - accuracy: 0.3580\n",
            "Epoch 342/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1042 - accuracy: 0.3560\n",
            "Epoch 343/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1032 - accuracy: 0.3565\n",
            "Epoch 344/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1022 - accuracy: 0.3565\n",
            "Epoch 345/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0995 - accuracy: 0.3568\n",
            "Epoch 346/800\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.1274 - accuracy: 0.3496\n",
            "Epoch 347/800\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.2365 - accuracy: 0.3173\n",
            "Epoch 348/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.8933 - accuracy: 0.1965\n",
            "Epoch 349/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.6192 - accuracy: 0.2444\n",
            "Epoch 350/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.4047 - accuracy: 0.2819\n",
            "Epoch 351/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.2730 - accuracy: 0.3121\n",
            "Epoch 352/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1849 - accuracy: 0.3345\n",
            "Epoch 353/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1493 - accuracy: 0.3439\n",
            "Epoch 354/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.1307 - accuracy: 0.3487\n",
            "Epoch 355/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.1187 - accuracy: 0.3536\n",
            "Epoch 356/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1112 - accuracy: 0.3553\n",
            "Epoch 357/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1063 - accuracy: 0.3559\n",
            "Epoch 358/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1033 - accuracy: 0.3566\n",
            "Epoch 359/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1006 - accuracy: 0.3571\n",
            "Epoch 360/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0984 - accuracy: 0.3576\n",
            "Epoch 361/800\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.0963 - accuracy: 0.3579\n",
            "Epoch 362/800\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.0944 - accuracy: 0.3585\n",
            "Epoch 363/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.0929 - accuracy: 0.3586\n",
            "Epoch 364/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0914 - accuracy: 0.3590\n",
            "Epoch 365/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0907 - accuracy: 0.3593\n",
            "Epoch 366/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0899 - accuracy: 0.3592\n",
            "Epoch 367/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0896 - accuracy: 0.3592\n",
            "Epoch 368/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0908 - accuracy: 0.3592\n",
            "Epoch 369/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.0901 - accuracy: 0.3589\n",
            "Epoch 370/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0887 - accuracy: 0.3596\n",
            "Epoch 371/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.1187 - accuracy: 0.3516\n",
            "Epoch 372/800\n",
            "100/100 [==============================] - 15s 148ms/step - loss: 0.1109 - accuracy: 0.3538\n",
            "Epoch 373/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0956 - accuracy: 0.3580\n",
            "Epoch 374/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0910 - accuracy: 0.3589\n",
            "Epoch 375/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0882 - accuracy: 0.3590\n",
            "Epoch 376/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.0851 - accuracy: 0.3597\n",
            "Epoch 377/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0839 - accuracy: 0.3597\n",
            "Epoch 378/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0833 - accuracy: 0.3601\n",
            "Epoch 379/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0828 - accuracy: 0.3605\n",
            "Epoch 380/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0829 - accuracy: 0.3602\n",
            "Epoch 381/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0857 - accuracy: 0.3600\n",
            "Epoch 382/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0854 - accuracy: 0.3592\n",
            "Epoch 383/800\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.0839 - accuracy: 0.3598\n",
            "Epoch 384/800\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.0835 - accuracy: 0.3600\n",
            "Epoch 385/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0839 - accuracy: 0.3603\n",
            "Epoch 386/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0839 - accuracy: 0.3596\n",
            "Epoch 387/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0832 - accuracy: 0.3605\n",
            "Epoch 388/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.0827 - accuracy: 0.3607\n",
            "Epoch 389/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0810 - accuracy: 0.3605\n",
            "Epoch 390/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0799 - accuracy: 0.3603\n",
            "Epoch 391/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.1524 - accuracy: 0.3458\n",
            "Epoch 392/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.4828 - accuracy: 0.2640\n",
            "Epoch 393/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1628 - accuracy: 0.3375\n",
            "Epoch 394/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.1106 - accuracy: 0.3532\n",
            "Epoch 395/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0924 - accuracy: 0.3587\n",
            "Epoch 396/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0848 - accuracy: 0.3604\n",
            "Epoch 397/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0802 - accuracy: 0.3612\n",
            "Epoch 398/800\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.0786 - accuracy: 0.3612\n",
            "Epoch 399/800\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.0767 - accuracy: 0.3617\n",
            "Epoch 400/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0755 - accuracy: 0.3619\n",
            "Epoch 401/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0744 - accuracy: 0.3619\n",
            "Epoch 402/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0739 - accuracy: 0.3618\n",
            "Epoch 403/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0735 - accuracy: 0.3620\n",
            "Epoch 404/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0730 - accuracy: 0.3623\n",
            "Epoch 405/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.0732 - accuracy: 0.3622\n",
            "Epoch 406/800\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.0735 - accuracy: 0.3617\n",
            "Epoch 407/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.0731 - accuracy: 0.3618\n",
            "Epoch 408/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0727 - accuracy: 0.3623\n",
            "Epoch 409/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0723 - accuracy: 0.3622\n",
            "Epoch 410/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0719 - accuracy: 0.3621\n",
            "Epoch 411/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0721 - accuracy: 0.3619\n",
            "Epoch 412/800\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.0738 - accuracy: 0.3618\n",
            "Epoch 413/800\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.0762 - accuracy: 0.3614\n",
            "Epoch 414/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0755 - accuracy: 0.3620\n",
            "Epoch 415/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0775 - accuracy: 0.3607\n",
            "Epoch 416/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0827 - accuracy: 0.3598\n",
            "Epoch 417/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0792 - accuracy: 0.3603\n",
            "Epoch 418/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0756 - accuracy: 0.3612\n",
            "Epoch 419/800\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 0.0729 - accuracy: 0.3618\n",
            "Epoch 420/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.0715 - accuracy: 0.3621\n",
            "Epoch 421/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0710 - accuracy: 0.3624\n",
            "Epoch 422/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0709 - accuracy: 0.3618\n",
            "Epoch 423/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0698 - accuracy: 0.3627\n",
            "Epoch 424/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1384 - accuracy: 0.3466\n",
            "Epoch 425/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.5237 - accuracy: 0.2543\n",
            "Epoch 426/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.3471 - accuracy: 0.2878\n",
            "Epoch 427/800\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.1975 - accuracy: 0.3273\n",
            "Epoch 428/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1191 - accuracy: 0.3506\n",
            "Epoch 429/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0951 - accuracy: 0.3578\n",
            "Epoch 430/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0848 - accuracy: 0.3603\n",
            "Epoch 431/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0796 - accuracy: 0.3611\n",
            "Epoch 432/800\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.0770 - accuracy: 0.3614\n",
            "Epoch 433/800\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 0.0741 - accuracy: 0.3618\n",
            "Epoch 434/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.0721 - accuracy: 0.3623\n",
            "Epoch 435/800\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.0710 - accuracy: 0.3622\n",
            "Epoch 436/800\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.0700 - accuracy: 0.3624\n",
            "Epoch 437/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.0693 - accuracy: 0.3624\n",
            "Epoch 438/800\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 0.0688 - accuracy: 0.3625\n",
            "Epoch 439/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.0683 - accuracy: 0.3628\n",
            "Epoch 440/800\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 0.0682 - accuracy: 0.3627\n",
            "Epoch 441/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0683 - accuracy: 0.3621\n",
            "Epoch 442/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0687 - accuracy: 0.3625\n",
            "Epoch 443/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0710 - accuracy: 0.3622\n",
            "Epoch 444/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0691 - accuracy: 0.3624\n",
            "Epoch 445/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.0701 - accuracy: 0.3623\n",
            "Epoch 446/800\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.0684 - accuracy: 0.3626\n",
            "Epoch 447/800\n",
            "100/100 [==============================] - 16s 154ms/step - loss: 0.0672 - accuracy: 0.3627\n",
            "Epoch 448/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0669 - accuracy: 0.3626\n",
            "Epoch 449/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.0671 - accuracy: 0.3627\n",
            "Epoch 450/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0670 - accuracy: 0.3623\n",
            "Epoch 451/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.0663 - accuracy: 0.3630\n",
            "Epoch 452/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0733 - accuracy: 0.3610\n",
            "Epoch 453/800\n",
            "100/100 [==============================] - 17s 165ms/step - loss: 0.0820 - accuracy: 0.3595\n",
            "Epoch 454/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0786 - accuracy: 0.3603\n",
            "Epoch 455/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0712 - accuracy: 0.3617\n",
            "Epoch 456/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0735 - accuracy: 0.3613\n",
            "Epoch 457/800\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 0.0723 - accuracy: 0.3612\n",
            "Epoch 458/800\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.0669 - accuracy: 0.3621\n",
            "Epoch 459/800\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 0.0652 - accuracy: 0.3628\n",
            "Epoch 460/800\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.0653 - accuracy: 0.3623\n",
            "Epoch 461/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.0808 - accuracy: 0.3586\n",
            "Epoch 462/800\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.0732 - accuracy: 0.3609\n",
            "Epoch 463/800\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.0667 - accuracy: 0.3627\n",
            "Epoch 464/800\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 0.0641 - accuracy: 0.3631\n",
            "Epoch 465/800\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 0.0659 - accuracy: 0.3622\n",
            "Epoch 466/800\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.0930 - accuracy: 0.3563\n",
            "Epoch 467/800\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.0781 - accuracy: 0.3598\n",
            "Epoch 468/800\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 0.0940 - accuracy: 0.3560\n",
            "Epoch 469/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.0803 - accuracy: 0.3594\n",
            "Epoch 470/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0690 - accuracy: 0.3621\n",
            "Epoch 471/800\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 0.0630 - accuracy: 0.3626\n",
            "Epoch 472/800\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.0601 - accuracy: 0.3634\n",
            "Epoch 473/800\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.0598 - accuracy: 0.3635\n",
            "Epoch 474/800\n",
            "100/100 [==============================] - 16s 164ms/step - loss: 0.0596 - accuracy: 0.3634\n",
            "Epoch 475/800\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.0593 - accuracy: 0.3635\n",
            "Epoch 476/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.0605 - accuracy: 0.3630\n",
            "Epoch 477/800\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 0.0612 - accuracy: 0.3634\n",
            "Epoch 478/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0609 - accuracy: 0.3633\n",
            "Epoch 479/800\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.0611 - accuracy: 0.3632\n",
            "Epoch 480/800\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.1276 - accuracy: 0.3472\n",
            "Epoch 481/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.4885 - accuracy: 0.2622\n",
            "Epoch 482/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.5726 - accuracy: 0.2517\n",
            "Epoch 483/800\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 0.1977 - accuracy: 0.3277\n",
            "Epoch 484/800\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.1149 - accuracy: 0.3508\n",
            "Epoch 485/800\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 0.0862 - accuracy: 0.3593\n",
            "Epoch 486/800\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.0756 - accuracy: 0.3618\n",
            "Epoch 487/800\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.0716 - accuracy: 0.3624\n",
            "Epoch 488/800\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.0677 - accuracy: 0.3628\n",
            "Epoch 489/800\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 0.0656 - accuracy: 0.3633\n",
            "Epoch 490/800\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 0.0636 - accuracy: 0.3635\n",
            "Epoch 491/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0624 - accuracy: 0.3634\n",
            "Epoch 492/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.0612 - accuracy: 0.3637\n",
            "Epoch 493/800\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.0599 - accuracy: 0.3639\n",
            "Epoch 494/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0592 - accuracy: 0.3637\n",
            "Epoch 495/800\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 0.0588 - accuracy: 0.3640\n",
            "Epoch 496/800\n",
            "100/100 [==============================] - 16s 164ms/step - loss: 0.0612 - accuracy: 0.3632\n",
            "Epoch 497/800\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 0.0590 - accuracy: 0.3638\n",
            "Epoch 498/800\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.0600 - accuracy: 0.3638\n",
            "Epoch 499/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.0584 - accuracy: 0.3638\n",
            "Epoch 500/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0574 - accuracy: 0.3638\n",
            "Epoch 501/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0566 - accuracy: 0.3638\n",
            "Epoch 502/800\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.0563 - accuracy: 0.3640\n",
            "Epoch 503/800\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 0.0562 - accuracy: 0.3638\n",
            "Epoch 504/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0566 - accuracy: 0.3643\n",
            "Epoch 505/800\n",
            "100/100 [==============================] - 15s 149ms/step - loss: 0.0576 - accuracy: 0.3640\n",
            "Epoch 506/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0569 - accuracy: 0.3636\n",
            "Epoch 507/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0560 - accuracy: 0.3638\n",
            "Epoch 508/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0553 - accuracy: 0.3637\n",
            "Epoch 509/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0686 - accuracy: 0.3618\n",
            "Epoch 510/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.1982 - accuracy: 0.3257\n",
            "Epoch 511/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.5390 - accuracy: 0.2611\n",
            "Epoch 512/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.2873 - accuracy: 0.3059\n",
            "Epoch 513/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1417 - accuracy: 0.3432\n",
            "Epoch 514/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0965 - accuracy: 0.3553\n",
            "Epoch 515/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0787 - accuracy: 0.3599\n",
            "Epoch 516/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0699 - accuracy: 0.3620\n",
            "Epoch 517/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.0647 - accuracy: 0.3630\n",
            "Epoch 518/800\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.0618 - accuracy: 0.3634\n",
            "Epoch 519/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0600 - accuracy: 0.3639\n",
            "Epoch 520/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0592 - accuracy: 0.3638\n",
            "Epoch 521/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0582 - accuracy: 0.3637\n",
            "Epoch 522/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0576 - accuracy: 0.3641\n",
            "Epoch 523/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0577 - accuracy: 0.3637\n",
            "Epoch 524/800\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.0573 - accuracy: 0.3638\n",
            "Epoch 525/800\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.0562 - accuracy: 0.3640\n",
            "Epoch 526/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0556 - accuracy: 0.3638\n",
            "Epoch 527/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0551 - accuracy: 0.3642\n",
            "Epoch 528/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0550 - accuracy: 0.3640\n",
            "Epoch 529/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0551 - accuracy: 0.3644\n",
            "Epoch 530/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0549 - accuracy: 0.3639\n",
            "Epoch 531/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0550 - accuracy: 0.3643\n",
            "Epoch 532/800\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.0546 - accuracy: 0.3644\n",
            "Epoch 533/800\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.0548 - accuracy: 0.3642\n",
            "Epoch 534/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0550 - accuracy: 0.3640\n",
            "Epoch 535/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0561 - accuracy: 0.3641\n",
            "Epoch 536/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0560 - accuracy: 0.3640\n",
            "Epoch 537/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.0561 - accuracy: 0.3641\n",
            "Epoch 538/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0561 - accuracy: 0.3639\n",
            "Epoch 539/800\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 0.0564 - accuracy: 0.3642\n",
            "Epoch 540/800\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 0.0597 - accuracy: 0.3633\n",
            "Epoch 541/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.2066 - accuracy: 0.3316\n",
            "Epoch 542/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.3023 - accuracy: 0.3022\n",
            "Epoch 543/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1274 - accuracy: 0.3451\n",
            "Epoch 544/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0839 - accuracy: 0.3576\n",
            "Epoch 545/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0656 - accuracy: 0.3623\n",
            "Epoch 546/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0593 - accuracy: 0.3637\n",
            "Epoch 547/800\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.0565 - accuracy: 0.3635\n",
            "Epoch 548/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.0555 - accuracy: 0.3640\n",
            "Epoch 549/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0552 - accuracy: 0.3640\n",
            "Epoch 550/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0541 - accuracy: 0.3640\n",
            "Epoch 551/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0533 - accuracy: 0.3641\n",
            "Epoch 552/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0529 - accuracy: 0.3644\n",
            "Epoch 553/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0527 - accuracy: 0.3644\n",
            "Epoch 554/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0528 - accuracy: 0.3645\n",
            "Epoch 555/800\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.0525 - accuracy: 0.3645\n",
            "Epoch 556/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0524 - accuracy: 0.3643\n",
            "Epoch 557/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0523 - accuracy: 0.3637\n",
            "Epoch 558/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0524 - accuracy: 0.3644\n",
            "Epoch 559/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.0521 - accuracy: 0.3641\n",
            "Epoch 560/800\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.0530 - accuracy: 0.3642\n",
            "Epoch 561/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0537 - accuracy: 0.3642\n",
            "Epoch 562/800\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.0527 - accuracy: 0.3644\n",
            "Epoch 563/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0607 - accuracy: 0.3628\n",
            "Epoch 564/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0615 - accuracy: 0.3631\n",
            "Epoch 565/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0642 - accuracy: 0.3620\n",
            "Epoch 566/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0617 - accuracy: 0.3626\n",
            "Epoch 567/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0588 - accuracy: 0.3637\n",
            "Epoch 568/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0552 - accuracy: 0.3640\n",
            "Epoch 569/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.0527 - accuracy: 0.3643\n",
            "Epoch 570/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0515 - accuracy: 0.3644\n",
            "Epoch 571/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0503 - accuracy: 0.3646\n",
            "Epoch 572/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0503 - accuracy: 0.3647\n",
            "Epoch 573/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0502 - accuracy: 0.3648\n",
            "Epoch 574/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0505 - accuracy: 0.3646\n",
            "Epoch 575/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0518 - accuracy: 0.3646\n",
            "Epoch 576/800\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.0538 - accuracy: 0.3639\n",
            "Epoch 577/800\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.1481 - accuracy: 0.3392\n",
            "Epoch 578/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.3653 - accuracy: 0.2876\n",
            "Epoch 579/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.2114 - accuracy: 0.3212\n",
            "Epoch 580/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.4262 - accuracy: 0.2755\n",
            "Epoch 581/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.1789 - accuracy: 0.3316\n",
            "Epoch 582/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.1156 - accuracy: 0.3503\n",
            "Epoch 583/800\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.0913 - accuracy: 0.3571\n",
            "Epoch 584/800\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 0.0784 - accuracy: 0.3598\n",
            "Epoch 585/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0713 - accuracy: 0.3619\n",
            "Epoch 586/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0666 - accuracy: 0.3628\n",
            "Epoch 587/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0636 - accuracy: 0.3628\n",
            "Epoch 588/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0621 - accuracy: 0.3633\n",
            "Epoch 589/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0599 - accuracy: 0.3637\n",
            "Epoch 590/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0584 - accuracy: 0.3638\n",
            "Epoch 591/800\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.0572 - accuracy: 0.3640\n",
            "Epoch 592/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.0560 - accuracy: 0.3642\n",
            "Epoch 593/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0554 - accuracy: 0.3642\n",
            "Epoch 594/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0545 - accuracy: 0.3641\n",
            "Epoch 595/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0557 - accuracy: 0.3641\n",
            "Epoch 596/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0539 - accuracy: 0.3641\n",
            "Epoch 597/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0525 - accuracy: 0.3645\n",
            "Epoch 598/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0521 - accuracy: 0.3642\n",
            "Epoch 599/800\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.0515 - accuracy: 0.3644\n",
            "Epoch 600/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0508 - accuracy: 0.3645\n",
            "Epoch 601/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0510 - accuracy: 0.3646\n",
            "Epoch 602/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0508 - accuracy: 0.3646\n",
            "Epoch 603/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0510 - accuracy: 0.3646\n",
            "Epoch 604/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0514 - accuracy: 0.3643\n",
            "Epoch 605/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0508 - accuracy: 0.3645\n",
            "Epoch 606/800\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.0507 - accuracy: 0.3644\n",
            "Epoch 607/800\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.0514 - accuracy: 0.3644\n",
            "Epoch 608/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0517 - accuracy: 0.3643\n",
            "Epoch 609/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0511 - accuracy: 0.3643\n",
            "Epoch 610/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0513 - accuracy: 0.3645\n",
            "Epoch 611/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0555 - accuracy: 0.3635\n",
            "Epoch 612/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0569 - accuracy: 0.3636\n",
            "Epoch 613/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.0551 - accuracy: 0.3637\n",
            "Epoch 614/800\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.0929 - accuracy: 0.3539\n",
            "Epoch 615/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.2729 - accuracy: 0.3139\n",
            "Epoch 616/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.3433 - accuracy: 0.2905\n",
            "Epoch 617/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.6686 - accuracy: 0.2354\n",
            "Epoch 618/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.3300 - accuracy: 0.2982\n",
            "Epoch 619/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1897 - accuracy: 0.3301\n",
            "Epoch 620/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.1333 - accuracy: 0.3447\n",
            "Epoch 621/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.1034 - accuracy: 0.3535\n",
            "Epoch 622/800\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.0883 - accuracy: 0.3570\n",
            "Epoch 623/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0779 - accuracy: 0.3601\n",
            "Epoch 624/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0716 - accuracy: 0.3616\n",
            "Epoch 625/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0677 - accuracy: 0.3627\n",
            "Epoch 626/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0642 - accuracy: 0.3631\n",
            "Epoch 627/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0611 - accuracy: 0.3636\n",
            "Epoch 628/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0591 - accuracy: 0.3639\n",
            "Epoch 629/800\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.0574 - accuracy: 0.3640\n",
            "Epoch 630/800\n",
            "100/100 [==============================] - 16s 154ms/step - loss: 0.0561 - accuracy: 0.3645\n",
            "Epoch 631/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0549 - accuracy: 0.3645\n",
            "Epoch 632/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0540 - accuracy: 0.3647\n",
            "Epoch 633/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0533 - accuracy: 0.3647\n",
            "Epoch 634/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0527 - accuracy: 0.3647\n",
            "Epoch 635/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0526 - accuracy: 0.3645\n",
            "Epoch 636/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0523 - accuracy: 0.3649\n",
            "Epoch 637/800\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.0515 - accuracy: 0.3648\n",
            "Epoch 638/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0514 - accuracy: 0.3646\n",
            "Epoch 639/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0512 - accuracy: 0.3649\n",
            "Epoch 640/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0506 - accuracy: 0.3648\n",
            "Epoch 641/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0504 - accuracy: 0.3647\n",
            "Epoch 642/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0501 - accuracy: 0.3646\n",
            "Epoch 643/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0498 - accuracy: 0.3648\n",
            "Epoch 644/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.0500 - accuracy: 0.3648\n",
            "Epoch 645/800\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.0499 - accuracy: 0.3645\n",
            "Epoch 646/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.0503 - accuracy: 0.3649\n",
            "Epoch 647/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0500 - accuracy: 0.3649\n",
            "Epoch 648/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0500 - accuracy: 0.3646\n",
            "Epoch 649/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0501 - accuracy: 0.3645\n",
            "Epoch 650/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0496 - accuracy: 0.3646\n",
            "Epoch 651/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0496 - accuracy: 0.3647\n",
            "Epoch 652/800\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 0.0506 - accuracy: 0.3645\n",
            "Epoch 653/800\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.0503 - accuracy: 0.3646\n",
            "Epoch 654/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0502 - accuracy: 0.3642\n",
            "Epoch 655/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0505 - accuracy: 0.3642\n",
            "Epoch 656/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0514 - accuracy: 0.3642\n",
            "Epoch 657/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0529 - accuracy: 0.3639\n",
            "Epoch 658/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0545 - accuracy: 0.3638\n",
            "Epoch 659/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0578 - accuracy: 0.3635\n",
            "Epoch 660/800\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.1293 - accuracy: 0.3433\n",
            "Epoch 661/800\n",
            "100/100 [==============================] - 16s 154ms/step - loss: 0.1184 - accuracy: 0.3473\n",
            "Epoch 662/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0794 - accuracy: 0.3577\n",
            "Epoch 663/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0587 - accuracy: 0.3633\n",
            "Epoch 664/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0516 - accuracy: 0.3645\n",
            "Epoch 665/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0499 - accuracy: 0.3645\n",
            "Epoch 666/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0490 - accuracy: 0.3646\n",
            "Epoch 667/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0496 - accuracy: 0.3646\n",
            "Epoch 668/800\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.0492 - accuracy: 0.3647\n",
            "Epoch 669/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0485 - accuracy: 0.3646\n",
            "Epoch 670/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0485 - accuracy: 0.3643\n",
            "Epoch 671/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0494 - accuracy: 0.3648\n",
            "Epoch 672/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0491 - accuracy: 0.3647\n",
            "Epoch 673/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0488 - accuracy: 0.3646\n",
            "Epoch 674/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0489 - accuracy: 0.3647\n",
            "Epoch 675/800\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 0.0490 - accuracy: 0.3647\n",
            "Epoch 676/800\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.0494 - accuracy: 0.3645\n",
            "Epoch 677/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0492 - accuracy: 0.3651\n",
            "Epoch 678/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0491 - accuracy: 0.3645\n",
            "Epoch 679/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0499 - accuracy: 0.3647\n",
            "Epoch 680/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0512 - accuracy: 0.3642\n",
            "Epoch 681/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0639 - accuracy: 0.3617\n",
            "Epoch 682/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1314 - accuracy: 0.3413\n",
            "Epoch 683/800\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.1178 - accuracy: 0.3468\n",
            "Epoch 684/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0705 - accuracy: 0.3602\n",
            "Epoch 685/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0562 - accuracy: 0.3632\n",
            "Epoch 686/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0507 - accuracy: 0.3643\n",
            "Epoch 687/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0480 - accuracy: 0.3647\n",
            "Epoch 688/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0471 - accuracy: 0.3652\n",
            "Epoch 689/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0470 - accuracy: 0.3650\n",
            "Epoch 690/800\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 0.0465 - accuracy: 0.3647\n",
            "Epoch 691/800\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.0464 - accuracy: 0.3651\n",
            "Epoch 692/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0465 - accuracy: 0.3650\n",
            "Epoch 693/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0464 - accuracy: 0.3648\n",
            "Epoch 694/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0469 - accuracy: 0.3649\n",
            "Epoch 695/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0468 - accuracy: 0.3650\n",
            "Epoch 696/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0465 - accuracy: 0.3653\n",
            "Epoch 697/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0468 - accuracy: 0.3652\n",
            "Epoch 698/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.0486 - accuracy: 0.3645\n",
            "Epoch 699/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.0495 - accuracy: 0.3644\n",
            "Epoch 700/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0493 - accuracy: 0.3647\n",
            "Epoch 701/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0701 - accuracy: 0.3594\n",
            "Epoch 702/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1363 - accuracy: 0.3404\n",
            "Epoch 703/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1430 - accuracy: 0.3391\n",
            "Epoch 704/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0869 - accuracy: 0.3552\n",
            "Epoch 705/800\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.0674 - accuracy: 0.3606\n",
            "Epoch 706/800\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.6303 - accuracy: 0.2439\n",
            "Epoch 707/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.2118 - accuracy: 0.3217\n",
            "Epoch 708/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1216 - accuracy: 0.3460\n",
            "Epoch 709/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.1587 - accuracy: 0.3432\n",
            "Epoch 710/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.6021 - accuracy: 0.2487\n",
            "Epoch 711/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.2548 - accuracy: 0.3122\n",
            "Epoch 712/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.1641 - accuracy: 0.3346\n",
            "Epoch 713/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.1227 - accuracy: 0.3475\n",
            "Epoch 714/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0996 - accuracy: 0.3547\n",
            "Epoch 715/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0865 - accuracy: 0.3586\n",
            "Epoch 716/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0782 - accuracy: 0.3603\n",
            "Epoch 717/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0729 - accuracy: 0.3616\n",
            "Epoch 718/800\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 0.0689 - accuracy: 0.3621\n",
            "Epoch 719/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0660 - accuracy: 0.3628\n",
            "Epoch 720/800\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 0.0640 - accuracy: 0.3630\n",
            "Epoch 721/800\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.0620 - accuracy: 0.3634\n",
            "Epoch 722/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0604 - accuracy: 0.3638\n",
            "Epoch 723/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0592 - accuracy: 0.3635\n",
            "Epoch 724/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0579 - accuracy: 0.3639\n",
            "Epoch 725/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0572 - accuracy: 0.3639\n",
            "Epoch 726/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0566 - accuracy: 0.3639\n",
            "Epoch 727/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0558 - accuracy: 0.3638\n",
            "Epoch 728/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.0552 - accuracy: 0.3640\n",
            "Epoch 729/800\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 0.0540 - accuracy: 0.3642\n",
            "Epoch 730/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.0532 - accuracy: 0.3642\n",
            "Epoch 731/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.0527 - accuracy: 0.3642\n",
            "Epoch 732/800\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 0.0521 - accuracy: 0.3645\n",
            "Epoch 733/800\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 0.0517 - accuracy: 0.3645\n",
            "Epoch 734/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.0514 - accuracy: 0.3642\n",
            "Epoch 735/800\n",
            "100/100 [==============================] - 17s 167ms/step - loss: 0.0511 - accuracy: 0.3645\n",
            "Epoch 736/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0509 - accuracy: 0.3643\n",
            "Epoch 737/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0505 - accuracy: 0.3644\n",
            "Epoch 738/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0501 - accuracy: 0.3645\n",
            "Epoch 739/800\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 0.0494 - accuracy: 0.3645\n",
            "Epoch 740/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0489 - accuracy: 0.3646\n",
            "Epoch 741/800\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.0484 - accuracy: 0.3650\n",
            "Epoch 742/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.0484 - accuracy: 0.3647\n",
            "Epoch 743/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0486 - accuracy: 0.3649\n",
            "Epoch 744/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0482 - accuracy: 0.3646\n",
            "Epoch 745/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0484 - accuracy: 0.3649\n",
            "Epoch 746/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0480 - accuracy: 0.3647\n",
            "Epoch 747/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0476 - accuracy: 0.3648\n",
            "Epoch 748/800\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 0.0473 - accuracy: 0.3649\n",
            "Epoch 749/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.0468 - accuracy: 0.3651\n",
            "Epoch 750/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0470 - accuracy: 0.3647\n",
            "Epoch 751/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0471 - accuracy: 0.3652\n",
            "Epoch 752/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0477 - accuracy: 0.3650\n",
            "Epoch 753/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0483 - accuracy: 0.3647\n",
            "Epoch 754/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0481 - accuracy: 0.3649\n",
            "Epoch 755/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0484 - accuracy: 0.3645\n",
            "Epoch 756/800\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.0483 - accuracy: 0.3648\n",
            "Epoch 757/800\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.0497 - accuracy: 0.3643\n",
            "Epoch 758/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0490 - accuracy: 0.3643\n",
            "Epoch 759/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0479 - accuracy: 0.3647\n",
            "Epoch 760/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0473 - accuracy: 0.3649\n",
            "Epoch 761/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0465 - accuracy: 0.3650\n",
            "Epoch 762/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0462 - accuracy: 0.3646\n",
            "Epoch 763/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.0444 - accuracy: 0.3651\n",
            "Epoch 764/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.0448 - accuracy: 0.3651\n",
            "Epoch 765/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0445 - accuracy: 0.3649\n",
            "Epoch 766/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.0468 - accuracy: 0.3651\n",
            "Epoch 767/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0559 - accuracy: 0.3625\n",
            "Epoch 768/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.2286 - accuracy: 0.3203\n",
            "Epoch 769/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.1564 - accuracy: 0.3351\n",
            "Epoch 770/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0829 - accuracy: 0.3556\n",
            "Epoch 771/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.0554 - accuracy: 0.3628\n",
            "Epoch 772/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0472 - accuracy: 0.3650\n",
            "Epoch 773/800\n",
            "100/100 [==============================] - 15s 152ms/step - loss: 0.0451 - accuracy: 0.3650\n",
            "Epoch 774/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0429 - accuracy: 0.3655\n",
            "Epoch 775/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0422 - accuracy: 0.3657\n",
            "Epoch 776/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0419 - accuracy: 0.3654\n",
            "Epoch 777/800\n",
            "100/100 [==============================] - 15s 151ms/step - loss: 0.0416 - accuracy: 0.3655\n",
            "Epoch 778/800\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.0412 - accuracy: 0.3656\n",
            "Epoch 779/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.0413 - accuracy: 0.3657\n",
            "Epoch 780/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0413 - accuracy: 0.3655\n",
            "Epoch 781/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0412 - accuracy: 0.3656\n",
            "Epoch 782/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0412 - accuracy: 0.3655\n",
            "Epoch 783/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0413 - accuracy: 0.3658\n",
            "Epoch 784/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0418 - accuracy: 0.3654\n",
            "Epoch 785/800\n",
            "100/100 [==============================] - 16s 163ms/step - loss: 0.0413 - accuracy: 0.3655\n",
            "Epoch 786/800\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 0.0408 - accuracy: 0.3658\n",
            "Epoch 787/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.0410 - accuracy: 0.3654\n",
            "Epoch 788/800\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.0409 - accuracy: 0.3655\n",
            "Epoch 789/800\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 0.0412 - accuracy: 0.3655\n",
            "Epoch 790/800\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 0.0414 - accuracy: 0.3657\n",
            "Epoch 791/800\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 0.0425 - accuracy: 0.3653\n",
            "Epoch 792/800\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.0439 - accuracy: 0.3650\n",
            "Epoch 793/800\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.0448 - accuracy: 0.3653\n",
            "Epoch 794/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0458 - accuracy: 0.3652\n",
            "Epoch 795/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0523 - accuracy: 0.3636\n",
            "Epoch 796/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0510 - accuracy: 0.3633\n",
            "Epoch 797/800\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 0.0472 - accuracy: 0.3647\n",
            "Epoch 798/800\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 0.0435 - accuracy: 0.3648\n",
            "Epoch 799/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0411 - accuracy: 0.3651\n",
            "Epoch 800/800\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 0.0400 - accuracy: 0.3653\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79554afa5540>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference setup\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))           # h input state has(256,1)shape\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))           # c input state has(256,1)shape\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs\n",
        ")\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states\n",
        ")\n"
      ],
      "metadata": {
        "id": "YDeaFzPsIJ4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to decode sequences\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1\n",
        "    target_seq = np.zeros((1, 1, target_vocab_size))\n",
        "    # Populate the first character of target sequence with the start character\n",
        "    target_seq[0, 0, target_char_index[' ']] = 1.0\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length or find the stop character\n",
        "        if sampled_char == '\\n' or len(decoded_sentence) > target_max_len:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (length 1)\n",
        "        target_seq = np.zeros((1, 1, target_vocab_size))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.0\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "# Test the model with first 10 input sequences\n",
        "for seq_index in range(20):\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print(f'Input: {input_texts[seq_index]}')\n",
        "    print(f'Decoded: {decoded_sentence}')\n",
        "    #print('---')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YBwIIB8LSzN",
        "outputId": "e611831e-b162-45cd-d5e3-523ce13e6229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "Input: Hi.\n",
            "Decoded: 즐튼!.....................\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Input: Run!\n",
            "Decoded: 좋닷......................\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Input: Run.\n",
            "Decoded: 짖네......................\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "Input: Who?\n",
            "Decoded: 즐튼!.....................\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Input: Wow!\n",
            "Decoded: 즐긴세요....................\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Input: Duck!\n",
            "Decoded: 좋닷!.....................\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Input: Fire!\n",
            "Decoded: 끄러워?....................\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Input: Help!\n",
            "Decoded: 쏜다......................\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Input: Hide.\n",
            "Decoded: 닷.......................\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Input: Jump!\n",
            "Decoded: 즐튼!.....................\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Input: Jump.\n",
            "Decoded: 짖네......................\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Input: Stay.\n",
            "Decoded: 말로세요....................\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Input: Wait!\n",
            "Decoded: 짖네......................\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Input: Wait!\n",
            "Decoded: 짖네......................\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Input: Wait.\n",
            "Decoded: 짖네......................\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Input: Begin.\n",
            "Decoded: 즐튼!.....................\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Input: Hello!\n",
            "Decoded: 좋닷......................\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "Input: Hello.\n",
            "Decoded: 즐튼!.....................\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Input: I see.\n",
            "Decoded: 짖네......................\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Input: I try.\n",
            "Decoded: 닷짖극.....................\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the traing result is poor, the test is terrible"
      ],
      "metadata": {
        "id": "Jjm2OkVccyqC"
      }
    }
  ]
}